{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02afaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kaggle python-dotenv pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec628f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6338b5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from a .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set Kaggle API credentials as environment variables\n",
    "KAGGLE_USERNAME = os.getenv('KAGGLE_USERNAME')\n",
    "KAGGLE_KEY= os.getenv('KAGGLE_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefbca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d chaudharisanika/smartphones-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf778de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip smartphones-dataset.zip -d smartphone-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c41de7",
   "metadata": {},
   "source": [
    "### SECTION 1: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711b3895",
   "metadata": {},
   "source": [
    "Q1. Load the dataset smartphones.csv using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fef0b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('smartphone-dataset/Smartphones_cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c513f5a",
   "metadata": {},
   "source": [
    "Q2. Display the shape of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411713a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38119497",
   "metadata": {},
   "source": [
    "Q3. Show the first 10 rows of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c91115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daf8869",
   "metadata": {},
   "source": [
    "Q4. Find all rows where the price is more than 30,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_price = df[df['price']>30000]\n",
    "high_price.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7561fdcc",
   "metadata": {},
   "source": [
    "Q5. Show all unique values in the Brand column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750bda4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = (df['brand_name'].unique())\n",
    "print(brands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea6510",
   "metadata": {},
   "source": [
    "Q6. Check for missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dcd46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b38bcd",
   "metadata": {},
   "source": [
    "Q7. Find the average RAM of all smartphones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426045ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ram = df['ram_capacity'].mean()\n",
    "print(avg_ram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66cab8",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "Q8. Count the number of phones per brand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a925d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_per_brand = df['brand_name'].value_counts()\n",
    "print(phone_per_brand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5970b1ed",
   "metadata": {},
   "source": [
    "Q9. Show the summary statistics for numeric columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57077ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee403f2a",
   "metadata": {},
   "source": [
    "Q10. Which line would show you correlation between numeric columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85171b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()\n",
    "df.corr(numeric_only=True).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6a4ca6",
   "metadata": {},
   "source": [
    "### SECTION 2: Visualization & Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cd1ae6",
   "metadata": {},
   "source": [
    "Q11. Import the required visualization libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa407f",
   "metadata": {},
   "source": [
    "Q12. Plot a histogram of Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888f95cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values if any\n",
    "prices = df['price']\n",
    "bins = 100000, 200000, 300000, 400000, 500000, 600000, 700000\n",
    "# Plot the histogram\n",
    "plt.hist(prices, color='skyblue', edgecolor='black', bins=bins)\n",
    "\n",
    "# Add title and axis labels\n",
    "plt.title(\"Histogram of Price\")\n",
    "plt.xlabel(\"Price Range\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a720ba13",
   "metadata": {},
   "source": [
    "Q13. Create a bar plot showing average price per brand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c215209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'brand' and calculate average price\n",
    "avg_price = df.groupby('brand_name')['price'].mean().sort_values(ascending=False)\n",
    "\n",
    "# Plot bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(avg_price.index, avg_price.values, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Average Price per Brand\")\n",
    "plt.xlabel(\"Brand\")\n",
    "plt.ylabel(\"Average Price\")\n",
    "\n",
    "# Rotate brand labels if needed\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbb0920",
   "metadata": {},
   "source": [
    "Q14. Plot a heatmap of correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43efacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr_matrix = df.corr(numeric_only=True)\n",
    "\n",
    "# Set the plot size and style\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Create the heatmap\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "\n",
    "# Add a title\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37313b07",
   "metadata": {},
   "source": [
    "Q15. Show the relationship between RAM and Price using a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a7c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['ram_capacity'], df['price'], color='teal', edgecolors='black')\n",
    "\n",
    "# Add title and axis labels\n",
    "plt.title(\"Relationship Between RAM and Price\")\n",
    "plt.xlabel(\"RAM (GB)\")\n",
    "plt.ylabel(\"Price\")\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b817507",
   "metadata": {},
   "source": [
    "Q16. Create a boxplot to visualize Price distribution across brands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38304ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the boxplot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=df, x='brand_name', y='price', color='Blue')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Price Distribution Across Brands\")\n",
    "plt.xlabel(\"Brand\")\n",
    "plt.ylabel(\"Price\")\n",
    "\n",
    "# Rotate x-axis labels if brand names are long\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d8a93f",
   "metadata": {},
   "source": [
    "Q17. Add a title to a plot."
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb958380",
   "metadata": {},
   "source": [
    "plt.title('Price Distribution by Brand')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ba368d",
   "metadata": {},
   "source": [
    "Q18. Plot a KDE (density plot) of prices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdafe402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot KDE of prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data=df, x='price', fill=True, color='purple')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Price Distribution (KDE)\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.savefig('pricekde.png')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cc9b13",
   "metadata": {},
   "source": [
    "Q19. Rotate x-axis labels for readability.\n",
    "\n",
    "Q20. Save a seaborn plot to a file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417c9f02",
   "metadata": {},
   "source": [
    "### SECTION 3: Regression & Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14b9e70",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "Q21. Import the required regression libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90179cc",
   "metadata": {},
   "source": [
    "Q22. Define features X and target y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d67e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f87d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = df.select_dtypes(include='object').columns\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb046020",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14251cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_columns:\n",
    "    df[col] = df[col].fillna(df[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbed1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8236a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c0b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df,columns=['brand_name', 'model', 'processor_brand', 'os'],drop_first=True).astype(int)\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b437bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop(columns=['price'])\n",
    "y = df_encoded['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1699b9",
   "metadata": {},
   "source": [
    "Q23. Split data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e86ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea18300",
   "metadata": {},
   "source": [
    "Q24. Train a linear regression model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b57e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f'intercept:{model.intercept_}\\n')\n",
    "print(f'slope:{model.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8442eb",
   "metadata": {},
   "source": [
    "Q25. Make predictions on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a8cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48703384",
   "metadata": {},
   "source": [
    "Q26. Calculate Mean Squared Error (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d09ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e12b54",
   "metadata": {},
   "source": [
    "Q27. Print R² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717fc91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ff94e5",
   "metadata": {},
   "source": [
    "Q28. Add a new feature: Price_per_GB = Price / Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf559a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded['price_per_gb'] = df_encoded['price']/df_encoded['internal_memory']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3625dd4f",
   "metadata": {},
   "source": [
    "Q29. Scale features using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64559b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# X_scaled =pd.DataFrame(scaler.fit_transform(df_encoded),columns=df_encoded.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4357a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the scaled result back to a DataFrame for easier comparison\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "X_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0515b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750dd93c",
   "metadata": {},
   "source": [
    "### SECTION 4: Feature Importance & Trend Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78550566",
   "metadata": {},
   "source": [
    "Q31. Get feature importances from a trained decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44581532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much each feature has helped in making decisions\n",
    "# Create a DataFrame for visualization\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': tree.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd09ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417ccfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and keep only the top 20 most important features\n",
    "top_n = 5\n",
    "importances_df = importances_df.sort_values(by='Importance', ascending=False).head(top_n)\n",
    "importances_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432f0a4a",
   "metadata": {},
   "source": [
    "Q32. Plot feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae2eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importances_df)\n",
    "plt.title(f'Top {top_n} Feature Importances')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207c3327",
   "metadata": {},
   "source": [
    "Q33. Select top 3 features using SelectKBest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909492a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SelectKBest\n",
    "selector = SelectKBest(score_func=f_regression, k=3)\n",
    "selector.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5772ea",
   "metadata": {},
   "source": [
    "Q34. Show the score of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bbe449",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selector.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b5dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of feature names and scores\n",
    "scores_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Score': selector.scores_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf6de02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by score and pick top 3\n",
    "top_features = scores_df.sort_values(by='Score', ascending=False).head(3)\n",
    "top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfaaf19",
   "metadata": {},
   "source": [
    "Q35. Drop irrelevant columns like Model_Name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeae668",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_col = df.drop(columns=['model'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e275f1",
   "metadata": {},
   "source": [
    "Q36. Sort data by RAM descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73096af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='ram_capacity', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f4b397",
   "metadata": {},
   "source": [
    "Q37. Filter phones with RAM > 8GB and Battery > 4000mAh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['ram_capacity'] > 8) & (df['battery_capacity'] > 4000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bd6bc",
   "metadata": {},
   "source": [
    "Q38. Group by Brand and get the average of all numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df8cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('brand_name').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca20289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b570af4",
   "metadata": {},
   "source": [
    "Q39. Count how many phones have dual SIM support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64d6073",
   "metadata": {},
   "source": [
    "Q40. Create a pairplot to examine pairwise feature trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bda919",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[['price', 'ram_capacity', 'battery_capacity', 'processor_speed']])\n",
    "plt.suptitle('Pairplot of Key Numeric Features', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129b1cab",
   "metadata": {},
   "source": [
    "### SECTION 5: Train-Test Split & Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33fdf4b",
   "metadata": {},
   "source": [
    "### Train-Test Split: Why & How\n",
    "#### Q41. Why do we split data into training and testing sets?\n",
    "\n",
    "A) To keep the dataset small\n",
    "\n",
    "B) To check if the model can memorize data\n",
    "\n",
    "C) To evaluate model performance on unseen data\n",
    "\n",
    "D) To make training faster\n",
    "\n",
    "#### Ans = C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc65a5c",
   "metadata": {},
   "source": [
    "We split our dataset into:\n",
    "\n",
    "- Training set - to teach the model\n",
    "\n",
    "- Testing set - to check how well it performs on new, unseen data\n",
    "\n",
    "This helps us know:\n",
    "\n",
    "- Is the model really learning patterns?\n",
    "\n",
    "- Or is it just memorizing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bc75d3",
   "metadata": {},
   "source": [
    "#### Q42. Fill in the code to split the data into 80% training and 20% testing.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#### Q43. What does random_state=42 do in train_test_split()?\n",
    "\n",
    "A) Speeds up the model\n",
    "\n",
    "B) Ensures reproducibility\n",
    "\n",
    "C) Shuffles the labels\n",
    "\n",
    "D) It’s required for all sklearn models\n",
    "\n",
    "#### Ans = B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95d7fec",
   "metadata": {},
   "source": [
    "When you do a train_test_split(), it randomly shuffles and splits your data.\n",
    "\n",
    "If you don't set random_state, you'll get different splits every time you run the code.\n",
    "\n",
    "But if you set,then:\n",
    "\n",
    "- You will always get the same split every time you run the code.\n",
    "\n",
    "- This makes your results reproducible and easier to debug or share."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f70146b",
   "metadata": {},
   "source": [
    "### Q44. What could happen if you evaluate your model on the same data it was trained on?\n",
    "\n",
    "A) You'll get accurate performance\n",
    "\n",
    "B) It will reflect real-world accuracy\n",
    "\n",
    "C) It will lead to overfitting and misleading results\n",
    "\n",
    "D) Nothing changes\n",
    "\n",
    "#### Ans = C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dfa4e9",
   "metadata": {},
   "source": [
    "If you evaluate your model on the same data it was trained on, it may perform very well but only because it memorized the answers.\n",
    "\n",
    "This gives you:\n",
    "\n",
    "- A false sense of accuracy\n",
    "\n",
    "- Results that don’t reflect how it will perform on new, unseen data\n",
    "\n",
    "That’s called overfitting — when the model learns the training data too well, including noise or specific examples, and fails on new data.\n",
    "\n",
    "In Machine Learning Terms:\n",
    "- A model that memorizes the training data = overfit\n",
    "- A model that learns the patterns = generalizes to new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1228363c",
   "metadata": {},
   "source": [
    "### Feature Scaling: Why & How\n",
    "\n",
    "#### Q45. Why do we scale features before training a model?\n",
    "\n",
    "A) To make the data easier to store\n",
    "\n",
    "B) To reduce RAM usage\n",
    "\n",
    "C) To ensure all features contribute equally\n",
    "\n",
    "D) To remove duplicates\n",
    "\n",
    "#### Ans = C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6746324",
   "metadata": {},
   "source": [
    "### Q46. What is the most common scaler used in regression problems?\n",
    "\n",
    "A) OneHotEncoder\n",
    "\n",
    "B) MinMaxScaler\n",
    "\n",
    "C) StandardScaler\n",
    "\n",
    "D) LabelEncoder\n",
    "\n",
    "#### Ans = C\n",
    "\n",
    "In regression problems, we care about:\n",
    "\n",
    "- Centering data (mean = 0)\n",
    "\n",
    "- Equal feature importance (standard deviation = 1)\n",
    "\n",
    "StandardScaler is the most common scaler because:\n",
    "\n",
    "- It keeps outliers under control (better than MinMaxScaler)\n",
    "\n",
    "- It makes models like Linear Regression and Ridge/Lasso work better\n",
    "\n",
    "- It's great when the data follows a normal distribution (or close to it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab6c5f1",
   "metadata": {},
   "source": [
    "#### Q47. Fill in the missing code to scale features using StandardScaler.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c85f43",
   "metadata": {},
   "source": [
    "### Q48. If a feature like RAM ranges from 2 to 16 and Battery ranges from 2000 to 6000, what problem could occur if not scaled?\n",
    "\n",
    "A) The RAM will dominate during training\n",
    "\n",
    "B) The model will always predict zeros\n",
    "\n",
    "C) Training will be faster\n",
    "\n",
    "D) Battery will be ignored completely\n",
    "\n",
    "#### Ans = A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartphone_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
